# M7 文件存储服务 - 自动清理机制

## 文档信息

**服务名称**: 文件存储服务 (file-service)  
**清理策略**: 定时清理 + 手动触发  
**清理条件**: 未使用且超过 30 天  
**版本**: v1.0

---

## 目录

1. [清理机制概述](#清理机制概述)
2. [清理策略](#清理策略)
3. [定时任务实现](#定时任务实现)
4. [清理流程](#清理流程)
5. [清理日志](#清理日志)
6. [手动触发](#手动触发)
7. [监控告警](#监控告警)
8. [常见问题](#常见问题)

---

## 清理机制概述

### 为什么需要自动清理

| 问题                 | 说明                                   | 解决方案       |
| -------------------- | -------------------------------------- | -------------- |
| **存储空间浪费**     | 用户上传后未使用的文件占用存储空间     | 定期自动清理   |
| **临时文件堆积**     | 编辑帖子时上传多张图片，最终只用一张   | 未使用文件清理 |
| **异常上传**         | 上传中断、测试上传等产生的垃圾文件     | 30 天自动清理  |

### 清理目标

- ✅ 自动清理未使用且超过 30 天的文件
- ✅ 已使用的文件永不清理（即使多年未访问）
- ✅ 批量处理，避免影响服务性能
- ✅ 完整的清理日志，可追溯

### 文件生命周期

```
上传 → 未使用 → (30天) → 自动清理 → 删除
       ↓
      被引用 → 已使用 → 永久保留
```

---

## 清理策略

### 清理条件

文件必须**同时满足**以下条件才会被清理：

| 条件           | 说明                          | 数据库字段         |
| -------------- | ----------------------------- | ------------------ |
| **状态未使用** | `status = 'unused'`           | `files.status`     |
| **上传超过 30 天** | `created_at < NOW() - 30 days` | `files.created_at` |

**SQL 查询**:

```sql
SELECT id, storage_key, file_size
FROM file_db.files
WHERE status = 'unused'
  AND created_at < CURRENT_TIMESTAMP - INTERVAL '30 days'
ORDER BY created_at
LIMIT 100;  -- 批量处理
```

### 不会被清理的文件

| 条件             | 说明                           |
| ---------------- | ------------------------------ |
| `status = 'used'` | 已被业务实体使用的文件         |
| 上传未满 30 天   | 保护期内的文件                 |
| 多次引用的文件   | 即使部分引用被删除，仍保留     |

---

## 定时任务实现

### 使用 tokio-cron-scheduler

```rust
// src/scheduler/cleanup_job.rs
use tokio_cron_scheduler::{Job, JobScheduler};
use std::sync::Arc;
use sqlx::PgPool;
use crate::storage::backend::StorageBackend;
use crate::services::cleanup_service::CleanupService;

/// 启动清理定时任务
pub async fn start_cleanup_job(
    db: Arc<PgPool>,
    storage: Arc<dyn StorageBackend>,
    config: &CleanupConfig,
) -> Result<()> {
    if !config.enabled {
        tracing::info!("Cleanup job is disabled");
        return Ok(());
    }

    let scheduler = JobScheduler::new().await?;

    // 创建定时任务
    let db_clone = db.clone();
    let storage_clone = storage.clone();
    let threshold_days = config.days_threshold;
    let batch_size = config.batch_size;

    let job = Job::new_async(config.cron_expression.as_str(), move |_uuid, _l| {
        let db = db_clone.clone();
        let storage = storage_clone.clone();

        Box::pin(async move {
            tracing::info!("Starting scheduled cleanup job");

            match CleanupService::cleanup_unused_files(
                &db,
                &storage,
                threshold_days,
                batch_size,
                false,  // dry_run = false
            ).await {
                Ok(result) => {
                    tracing::info!(
                        files_deleted = result.files_deleted,
                        space_freed = result.space_freed,
                        duration_ms = result.duration_ms,
                        "Cleanup job completed successfully"
                    );
                }
                Err(e) => {
                    tracing::error!(error = %e, "Cleanup job failed");
                }
            }
        })
    })?;

    scheduler.add(job).await?;
    scheduler.start().await?;

    tracing::info!(
        cron = config.cron_expression,
        "Cleanup job scheduled"
    );

    Ok(())
}
```

### 配置参数

```rust
// src/config.rs
#[derive(Debug, Clone, Deserialize)]
pub struct CleanupConfig {
    pub enabled: bool,              // 是否启用自动清理
    pub cron_expression: String,    // Cron 表达式
    pub days_threshold: i32,        // 天数阈值（默认 30）
    pub batch_size: usize,          // 每批处理数量（默认 100）
}

impl CleanupConfig {
    pub fn from_env() -> Self {
        Self {
            enabled: std::env::var("CLEANUP_ENABLED")
                .unwrap_or_else(|_| "true".to_string())
                .parse()
                .unwrap_or(true),
            cron_expression: std::env::var("CLEANUP_CRON")
                .unwrap_or_else(|_| "0 0 2 * * *".to_string()),  // 每天凌晨 2:00
            days_threshold: std::env::var("CLEANUP_DAYS_THRESHOLD")
                .unwrap_or_else(|_| "30".to_string())
                .parse()
                .unwrap_or(30),
            batch_size: std::env::var("CLEANUP_BATCH_SIZE")
                .unwrap_or_else(|_| "100".to_string())
                .parse()
                .unwrap_or(100),
        }
    }
}
```

### Cron 表达式说明

```
 ┌───────────── 秒 (0-59)
 │ ┌─────────── 分 (0-59)
 │ │ ┌───────── 时 (0-23)
 │ │ │ ┌─────── 日 (1-31)
 │ │ │ │ ┌───── 月 (1-12)
 │ │ │ │ │ ┌─── 星期 (0-6, 0=周日)
 │ │ │ │ │ │
 * * * * * *
```

**示例**:

| Cron 表达式     | 说明                 |
| --------------- | -------------------- |
| `0 0 2 * * *`   | 每天凌晨 2:00        |
| `0 0 */6 * * *` | 每 6 小时执行一次    |
| `0 0 0 1 * *`   | 每月 1 号凌晨 0:00   |

---

## 清理流程

### 清理服务实现

```rust
// src/services/cleanup_service.rs
use sqlx::PgPool;
use std::sync::Arc;
use chrono::Utc;
use crate::storage::backend::StorageBackend;
use crate::models::cleanup_log::CleanupLog;

pub struct CleanupService;

#[derive(Debug)]
pub struct CleanupResult {
    pub files_deleted: i32,
    pub space_freed: i64,
    pub duration_ms: i64,
    pub status: String,
    pub errors: Vec<String>,
}

impl CleanupService {
    /// 清理未使用文件
    pub async fn cleanup_unused_files(
        db: &PgPool,
        storage: &Arc<dyn StorageBackend>,
        days_threshold: i32,
        batch_size: usize,
        dry_run: bool,
    ) -> Result<CleanupResult> {
        let start_time = Utc::now();
        let mut files_deleted = 0;
        let mut space_freed: i64 = 0;
        let mut errors = Vec::new();

        loop {
            // 1. 查询待清理文件（批量）
            let files = Self::fetch_files_to_cleanup(db, days_threshold, batch_size).await?;

            if files.is_empty() {
                break;
            }

            tracing::info!(
                batch_size = files.len(),
                "Found files to cleanup"
            );

            // 2. 处理每个文件
            for file in files {
                if dry_run {
                    // 仅列出，不删除
                    tracing::info!(
                        file_id = %file.id,
                        storage_key = file.storage_key,
                        size = file.file_size,
                        "Would delete file (dry run)"
                    );
                    files_deleted += 1;
                    space_freed += file.file_size;
                    continue;
                }

                // 3. 从存储后端删除物理文件
                match storage.delete(&file.storage_key).await {
                    Ok(_) => {
                        tracing::debug!(
                            file_id = %file.id,
                            storage_key = file.storage_key,
                            "File deleted from storage"
                        );

                        // 4. 更新数据库状态
                        match Self::mark_file_deleted(db, &file.id).await {
                            Ok(_) => {
                                files_deleted += 1;
                                space_freed += file.file_size;
                            }
                            Err(e) => {
                                let error_msg = format!(
                                    "Failed to mark file {} as deleted: {}",
                                    file.id, e
                                );
                                tracing::error!(error_msg);
                                errors.push(error_msg);
                            }
                        }
                    }
                    Err(e) => {
                        let error_msg = format!(
                            "Failed to delete file {} from storage: {}",
                            file.id, e
                        );
                        tracing::error!(error_msg);
                        errors.push(error_msg);
                    }
                }
            }

            // 批量处理，避免一次处理太多
            if files.len() < batch_size {
                break;
            }
        }

        let duration = Utc::now().signed_duration_since(start_time);
        let duration_ms = duration.num_milliseconds();

        let status = if errors.is_empty() {
            "success".to_string()
        } else if files_deleted > 0 {
            "partial".to_string()
        } else {
            "failed".to_string()
        };

        let result = CleanupResult {
            files_deleted,
            space_freed,
            duration_ms,
            status: status.clone(),
            errors: errors.clone(),
        };

        // 5. 记录清理日志
        if !dry_run {
            Self::log_cleanup(db, &result).await?;
        }

        Ok(result)
    }

    /// 查询待清理文件
    async fn fetch_files_to_cleanup(
        db: &PgPool,
        days_threshold: i32,
        limit: usize,
    ) -> Result<Vec<FileToCleanup>> {
        let files = sqlx::query_as!(
            FileToCleanup,
            r#"
            SELECT id, storage_key, file_size
            FROM file_db.files
            WHERE status = 'unused'
              AND created_at < CURRENT_TIMESTAMP - INTERVAL '$1 days'
            ORDER BY created_at
            LIMIT $2
            "#,
            days_threshold,
            limit as i64
        )
        .fetch_all(db)
        .await?;

        Ok(files)
    }

    /// 标记文件为已删除
    async fn mark_file_deleted(db: &PgPool, file_id: &Uuid) -> Result<()> {
        sqlx::query!(
            r#"
            UPDATE file_db.files
            SET status = 'deleted', updated_at = CURRENT_TIMESTAMP
            WHERE id = $1
            "#,
            file_id
        )
        .execute(db)
        .await?;

        // 删除使用关联（如果有）
        sqlx::query!(
            r#"
            DELETE FROM file_db.file_usages
            WHERE file_id = $1
            "#,
            file_id
        )
        .execute(db)
        .await?;

        Ok(())
    }

    /// 记录清理日志
    async fn log_cleanup(db: &PgPool, result: &CleanupResult) -> Result<()> {
        let error_message = if result.errors.is_empty() {
            None
        } else {
            Some(result.errors.join("; "))
        };

        sqlx::query!(
            r#"
            INSERT INTO file_db.cleanup_logs (
                cleanup_time,
                files_deleted,
                space_freed,
                duration_ms,
                status,
                error_message
            ) VALUES ($1, $2, $3, $4, $5, $6)
            "#,
            Utc::now().naive_utc(),
            result.files_deleted,
            result.space_freed,
            result.duration_ms as i32,
            result.status,
            error_message
        )
        .execute(db)
        .await?;

        Ok(())
    }
}

#[derive(Debug)]
struct FileToCleanup {
    id: Uuid,
    storage_key: String,
    file_size: i64,
}
```

### 清理流程图

```
┌──────────────────────────────────────────┐
│  1. 查询未使用且超过 30 天的文件         │
│     WHERE status = 'unused'              │
│     AND created_at < NOW() - 30 days     │
│     LIMIT 100                            │
└────────────────┬─────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────┐
│  2. 遍历每个文件                         │
└────────────────┬─────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────┐
│  3. 从存储后端删除物理文件               │
│     storage.delete(storage_key)          │
└────────────────┬─────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────┐
│  4. 更新数据库状态                       │
│     UPDATE files SET status = 'deleted'  │
│     DELETE FROM file_usages              │
└────────────────┬─────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────┐
│  5. 记录清理日志                         │
│     INSERT INTO cleanup_logs             │
└──────────────────────────────────────────┘
```

---

## 清理日志

### 日志表结构

```sql
CREATE TABLE file_db.cleanup_logs (
    id SERIAL PRIMARY KEY,
    cleanup_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    files_deleted INTEGER NOT NULL DEFAULT 0,
    space_freed BIGINT NOT NULL DEFAULT 0,
    duration_ms INTEGER,
    status VARCHAR(20) NOT NULL DEFAULT 'success',
    error_message TEXT
);
```

### 日志查询

#### 查看最近的清理记录

```sql
SELECT 
    id,
    cleanup_time,
    files_deleted,
    pg_size_pretty(space_freed::bigint) as space_freed,
    duration_ms,
    status
FROM file_db.cleanup_logs
ORDER BY cleanup_time DESC
LIMIT 10;
```

#### 统计清理效果

```sql
-- 总清理文件数和释放空间
SELECT 
    SUM(files_deleted) as total_files_deleted,
    pg_size_pretty(SUM(space_freed)::bigint) as total_space_freed,
    AVG(duration_ms) as avg_duration_ms
FROM file_db.cleanup_logs
WHERE status = 'success';

-- 按月统计
SELECT 
    DATE_TRUNC('month', cleanup_time) as month,
    SUM(files_deleted) as files_deleted,
    pg_size_pretty(SUM(space_freed)::bigint) as space_freed
FROM file_db.cleanup_logs
GROUP BY month
ORDER BY month DESC;
```

#### 查看失败记录

```sql
SELECT 
    id,
    cleanup_time,
    status,
    error_message
FROM file_db.cleanup_logs
WHERE status IN ('partial', 'failed')
ORDER BY cleanup_time DESC;
```

---

## 手动触发

### API 接口

参见 [02-API接口设计.md](./02-API接口设计.md#9-手动触发清理管理员)

### Handler 实现

```rust
// src/handlers/cleanup.rs
use actix_web::{web, HttpRequest, HttpResponse};
use serde::{Deserialize, Serialize};

#[derive(Debug, Deserialize)]
pub struct CleanupRequest {
    pub dry_run: Option<bool>,  // 默认 false
}

#[derive(Debug, Serialize)]
pub struct CleanupResponse {
    pub files_deleted: i32,
    pub space_freed: i64,
    pub space_freed_pretty: String,
    pub duration_ms: i64,
    pub status: String,
    pub errors: Vec<String>,
}

pub async fn cleanup_handler(
    req: HttpRequest,
    payload: web::Json<CleanupRequest>,
    db: web::Data<PgPool>,
    storage: web::Data<Arc<dyn StorageBackend>>,
    config: web::Data<CleanupConfig>,
) -> Result<HttpResponse, FileError> {
    // 1. 验证管理员权限
    if !is_admin(&req)? {
        return Err(FileError::Forbidden);
    }

    let dry_run = payload.dry_run.unwrap_or(false);

    // 2. 执行清理
    let result = CleanupService::cleanup_unused_files(
        &db,
        &storage,
        config.days_threshold,
        config.batch_size,
        dry_run,
    ).await?;

    // 3. 返回结果
    Ok(HttpResponse::Ok().json(CleanupResponse {
        files_deleted: result.files_deleted,
        space_freed: result.space_freed,
        space_freed_pretty: format_size(result.space_freed),
        duration_ms: result.duration_ms,
        status: result.status,
        errors: result.errors,
    }))
}

fn format_size(bytes: i64) -> String {
    const KB: i64 = 1024;
    const MB: i64 = KB * 1024;
    const GB: i64 = MB * 1024;

    if bytes >= GB {
        format!("{:.2} GB", bytes as f64 / GB as f64)
    } else if bytes >= MB {
        format!("{:.2} MB", bytes as f64 / MB as f64)
    } else if bytes >= KB {
        format!("{:.2} KB", bytes as f64 / KB as f64)
    } else {
        format!("{} bytes", bytes)
    }
}
```

### 使用示例

```bash
# 模拟运行（不实际删除）
curl -X POST http://localhost:8007/api/files/cleanup \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"dry_run": true}'

# 实际清理
curl -X POST http://localhost:8007/api/files/cleanup \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"dry_run": false}'
```

---

## 监控告警

### Prometheus 指标

```rust
// src/metrics.rs
use prometheus::{IntCounter, IntGauge, Histogram, register_int_counter, register_int_gauge, register_histogram};

lazy_static! {
    pub static ref CLEANUP_FILES_DELETED: IntCounter = register_int_counter!(
        "file_cleanup_files_deleted_total",
        "Total number of files deleted by cleanup job"
    ).unwrap();

    pub static ref CLEANUP_SPACE_FREED: IntCounter = register_int_counter!(
        "file_cleanup_space_freed_bytes_total",
        "Total space freed by cleanup job in bytes"
    ).unwrap();

    pub static ref CLEANUP_DURATION: Histogram = register_histogram!(
        "file_cleanup_duration_seconds",
        "Duration of cleanup job in seconds"
    ).unwrap();

    pub static ref UNUSED_FILES_COUNT: IntGauge = register_int_gauge!(
        "file_unused_files_count",
        "Number of unused files"
    ).unwrap();
}

// 在清理服务中使用
impl CleanupService {
    pub async fn cleanup_unused_files(...) -> Result<CleanupResult> {
        let timer = CLEANUP_DURATION.start_timer();

        // ... 清理逻辑 ...

        CLEANUP_FILES_DELETED.inc_by(result.files_deleted as u64);
        CLEANUP_SPACE_FREED.inc_by(result.space_freed as u64);
        timer.observe_duration();

        Ok(result)
    }
}
```

### Grafana 监控面板

**清理效果监控**:

```promql
# 每小时清理文件数
rate(file_cleanup_files_deleted_total[1h])

# 每小时释放空间
rate(file_cleanup_space_freed_bytes_total[1h])

# 清理任务时长
histogram_quantile(0.95, file_cleanup_duration_seconds)
```

### 告警规则

```yaml
# prometheus-alerts.yml
groups:
  - name: file-cleanup
    rules:
      - alert: CleanupJobFailed
        expr: file_cleanup_duration_seconds == 0
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Cleanup job not running"
          description: "Cleanup job has not run in the last hour"

      - alert: TooManyUnusedFiles
        expr: file_unused_files_count > 1000
        for: 6h
        labels:
          severity: warning
        annotations:
          summary: "Too many unused files"
          description: "{{ $value }} unused files detected"
```

---

## 常见问题

### Q1: 清理任务占用太多资源怎么办？

**解决**:

1. 减小 `batch_size`（如从 100 降到 50）
2. 调整 Cron 表达式为非高峰时段
3. 增加处理间隔，避免连续处理

```bash
# 每批处理 50 个文件
CLEANUP_BATCH_SIZE=50

# 改为每 6 小时执行一次
CLEANUP_CRON="0 0 */6 * * *"
```

### Q2: 如何恢复误删的文件？

**回答**: 

- 物理文件已从存储后端删除，无法恢复
- 文件元数据标记为 `deleted`，可查询但无法访问
- **建议**: 生产环境启用 S3 版本控制，保留历史版本

### Q3: 清理任务卡住怎么办？

**排查**:

1. 查看日志: `docker logs file-service`
2. 检查数据库连接: `psql -U open436 -d open436_db`
3. 检查存储后端: 访问 Minio 控制台
4. 重启服务: `docker restart file-service`

### Q4: 如何暂停自动清理？

**方法 1**: 环境变量

```bash
CLEANUP_ENABLED=false
```

**方法 2**: 重启服务

```bash
docker restart file-service
```

### Q5: 清理日志如何清理？

**建议**:

- 保留最近 1 年的日志
- 定期归档或删除旧日志

```sql
-- 删除 1 年前的清理日志
DELETE FROM file_db.cleanup_logs
WHERE cleanup_time < CURRENT_TIMESTAMP - INTERVAL '1 year';
```

---

## 测试清理功能

### 单元测试

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_fetch_files_to_cleanup() {
        let db = setup_test_db().await;

        // 创建测试数据
        insert_test_file(&db, "unused", -31).await;  // 31 天前
        insert_test_file(&db, "unused", -15).await;  // 15 天前
        insert_test_file(&db, "used", -31).await;    // 已使用

        // 查询待清理文件
        let files = CleanupService::fetch_files_to_cleanup(&db, 30, 100).await.unwrap();

        // 应该只返回 1 个文件（未使用且 > 30 天）
        assert_eq!(files.len(), 1);
    }

    #[tokio::test]
    async fn test_cleanup_dry_run() {
        let db = setup_test_db().await;
        let storage = setup_test_storage().await;

        // 插入测试数据
        insert_test_file(&db, "unused", -31).await;

        // 模拟运行
        let result = CleanupService::cleanup_unused_files(
            &db,
            &storage,
            30,
            100,
            true,  // dry_run
        ).await.unwrap();

        assert_eq!(result.files_deleted, 1);
        assert_eq!(result.status, "success");

        // 验证文件未被实际删除
        let file = query_file(&db).await.unwrap();
        assert_eq!(file.status, "unused");  // 状态未变
    }
}
```

### 集成测试

```bash
# 1. 上传测试文件
curl -X POST http://localhost:8007/api/files/upload \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@test.jpg" \
  -F "file_type=post"

# 2. 修改数据库（模拟 31 天前上传）
psql -U open436 -d open436_db -c \
  "UPDATE file_db.files SET created_at = created_at - INTERVAL '31 days' WHERE id = '...'"

# 3. 手动触发清理（dry run）
curl -X POST http://localhost:8007/api/files/cleanup \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"dry_run": true}'

# 4. 实际清理
curl -X POST http://localhost:8007/api/files/cleanup \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"dry_run": false}'

# 5. 验证文件已删除
curl http://localhost:8007/api/files/...
# 应返回 404
```

---

**文档版本**: v1.0  
**创建日期**: 2025-10-28  
**最后更新**: 2025-10-28

